{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EOSC 442 - Final Project</h1>\n",
    "Members: Isaiah Youm, Bernice Huynh, Ting Gu, Yicheng Ma\n",
    "\n",
    "Research Objective: // TODO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to manage data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>List of Functions Used</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts year and month gathered from dataset into datetime\n",
    "def convert_to_datetime(year:str, month:str, index:int, DataFrame:pd.DataFrame) -> datetime.date:\n",
    "    \"\"\"\n",
    "    year = Name of Column of Year in String (Column from DataFrame)\\n\n",
    "    month = Name of Column of Month in String (Column from DataFrame)\\n\n",
    "    index = the iteration number in a loop\\n\n",
    "    DataFrame = the target pandas.DataFrame\\n\n",
    "    \"\"\"\n",
    "    years = str(int(DataFrame.iloc[index][year]))\n",
    "    months = str(int(DataFrame.iloc[index][month]))\n",
    "    form_prep = years+'/'+months\n",
    "    date_time = datetime.strptime(form_prep, '%Y/%m')\n",
    "\n",
    "    return date_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3> Setting up Data for Ice Extent </h3>\n",
    "\n",
    "The csv file for the ice-extent data are separated by 12 months, which have their respective years from 1979 to 2022.\n",
    "The year and month, however, are separated and do not have a proper index.\n",
    "Therefore, when setting up this data, combining the month and year to a useable DateTime index is necessary.\n",
    "\n",
    "<strong> Throughout this data analysis, all DateTime index should be in the form of YYYY-MM-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             area data-type  extent region\n",
      "DateTime                                  \n",
      "1978-11-01   9.04   Goddard   11.65      N\n",
      "1978-12-01  10.90   Goddard   13.67      N\n",
      "1979-01-01  12.41   Goddard   15.41      N\n",
      "1979-02-01  13.18   Goddard   16.18      N\n",
      "1979-03-01  13.21   Goddard   16.34      N\n",
      "...           ...       ...     ...    ...\n",
      "2022-05-01  11.06   NRTSI-G   12.88      N\n",
      "2022-06-01   8.60   NRTSI-G   10.86      N\n",
      "2022-07-01   5.89   NRTSI-G    8.25      N\n",
      "2022-08-01   4.02   NRTSI-G    5.99      N\n",
      "2022-09-01   3.43   NRTSI-G    4.87      N\n",
      "\n",
      "[527 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Setting-up data for Ice-Extent.\n",
    "# NOTE: The csv file for the ice-extent data are separated by 12 months, which have their respective years from 1979 to 2022\n",
    "\n",
    "\n",
    "# Create an empty DataFrame for the Ice-Extent data.\n",
    "# Initiailizing the column names, because the pd.concat() function only works with data\n",
    "# that have the same parameters/columns.\n",
    "ice_extent = pd.DataFrame()\n",
    "\n",
    "# For-loop through the twelve datasets\n",
    "for num in range(1, 13):\n",
    "    if num < 10:\n",
    "        relative_file_path = f'./Ice Extent/N_0{num}_extent_v3.0.csv'\n",
    "    else:\n",
    "        relative_file_path = f'./Ice Extent/N_{num}_extent_v3.0.csv'\n",
    "    data_point = pd.read_csv(relative_file_path, delimiter=',\\s+', engine='python')\n",
    "    # print(data_point)\n",
    "    ice_extent = pd.concat([ice_extent, data_point], sort=True)\n",
    "\n",
    "##############\n",
    "\n",
    "# Have to change the ice_extent data to index it by YYYY_MM\n",
    "\n",
    "# To do this, we first need to grab the year and mo to DateTime format.\n",
    "datetime_iceextent = []\n",
    "for num in range(0, len(ice_extent)):\n",
    "    date_time = convert_to_datetime('year', 'mo', num, ice_extent)\n",
    "    datetime_iceextent.append(date_time)\n",
    "\n",
    "# Add list of datetime made to the Ice Extent DataFrame as 'DateTime'\n",
    "ice_extent['DateTime'] = datetime_iceextent\n",
    "\n",
    "# Set using pandas.DataFrame.set_index(column_name)\n",
    "ice_extent = ice_extent.set_index('DateTime')\n",
    "\n",
    "# Sort the data by DateTime (ascending chronological order)\n",
    "ice_extent = ice_extent.sort_index()\n",
    "\n",
    "# Delete redundant columns (year and mo in this case)\n",
    "ice_extent = ice_extent.drop('year', axis=1)\n",
    "ice_extent = ice_extent.drop('mo', axis=1)\n",
    "\n",
    "# Create the DataFrame for the ice extent\n",
    "extent = ice_extent['extent']\n",
    "\n",
    "# Create the DataFrame for the ice area\n",
    "ice_area = ice_extent['area']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3> Setting up Data for Ice Thickness</h3>\n",
    "\n",
    "<h5>Data Parameters:</h6>\n",
    "<hr>\n",
    "<pre>\n",
    "AIR-EM_summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns'\n",
    "- Data Range: \n",
    "2001 ~ 2005\n",
    "- Missing Values:\n",
    "-999.00, +-0.00 (Min_thkns)\n",
    "</pre>\n",
    "<hr>\n",
    "<pre>\n",
    "CanCoast_summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns' 'Avg_snow' 'Min_snow' 'Max_snow' 'SD_snow'\n",
    "- Data Range:\n",
    "1947 ~ 2013\n",
    "- Missing Value: \n",
    "-999.00\n",
    "</pre>\n",
    "<hr>\n",
    "<pre>\n",
    "CryoSat-AWI_summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns'\n",
    "- Data Range:\n",
    "2010 ~ 2016\n",
    "- Missing Value:\n",
    "-999\n",
    "</pre>\n",
    "<hr>\n",
    "<pre>\n",
    "IceBridge-QL.summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns' 'Avg_snow' 'Min_snow' 'Max_snow' 'SD_snow'\n",
    "- Data Range:\n",
    "2012 ~ 2015\n",
    "</pre>\n",
    "<hr>\n",
    "<pre>\n",
    "IceBridge-V2.summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns' 'Avg_snow' 'Min_snow' 'Max_snow' 'SD_snow'\n",
    "- Data Range:\n",
    "2009 ~ 2013\n",
    "</pre>\n",
    "<hr>\n",
    "<pre>\n",
    "ICESAT1-G_summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns'\n",
    "- Data Range:\n",
    "2003 ~ 2008\n",
    "- Missing Value:\n",
    "-999.00, +-0.00 (Min_thkns)\n",
    "</pre>\n",
    "<hr>\n",
    "<pre>\n",
    "ICESAT1-SH_summaries:\n",
    "\n",
    "- Parameters:\n",
    "'Year' 'Month' 'Lat' 'Lon' 'Avg_thkns' 'Min_thkns' 'Max_thkns' 'SD_thkns'\n",
    "- Data Range:\n",
    "2003 ~ 2008\n",
    "- Missing Value:\n",
    "-999.00, -5.00 & 0.00 (Min_thkns)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime\n",
      "1947-09-01    0.16\n",
      "1947-10-01    0.38\n",
      "1947-10-01    0.47\n",
      "1947-11-01    0.61\n",
      "1947-11-01    0.76\n",
      "              ... \n",
      "2016-02-01    1.49\n",
      "2016-02-01    1.39\n",
      "2016-02-01    2.45\n",
      "2016-02-01    3.90\n",
      "2016-02-01    2.06\n",
      "Name: Max_thkns, Length: 184728, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Setting-up data for Ice Thickness\n",
    "# There are multiple data sets that we need to add together.\n",
    "# We will make a DataFrame and designate a common parameter for all of them, then add all the data together.\n",
    "# (Because pd.concat() only works if the columns are the same)\n",
    "\n",
    "# Create empty DataFrame that will store all of the data\n",
    "ice_thickness = pd.DataFrame()\n",
    "\n",
    "# Create a list that contains the name of the text files we'll iterate.\n",
    "ice_thickness_names = ['./Ice Thickness/AIR-EM_summaries.txt', './Ice Thickness/CanCoast_summaries.txt', './Ice Thickness/CryoSat-AWI_summaries.txt', './Ice Thickness/IceBridge-QL.summaries.txt', './Ice Thickness/IceBridge-V2.summaries.txt', './Ice Thickness/ICESAT1-G_summaries.txt', './Ice Thickness/ICESAT1-SH_summaries.txt']\n",
    "\n",
    "\n",
    "# Compound all of the data together\n",
    "for csvnames in ice_thickness_names:\n",
    "    df = pd.read_csv(csvnames, usecols=[3, 7, 8, 9, 24, 25, 26, 27], sep='\\s+', engine='python')\n",
    "    ice_thickness = pd.concat([ice_thickness, df], sort=True)\n",
    "\n",
    "# Set index and \n",
    "\n",
    "# Have to change data to index it by YYYY_MM\n",
    "datetime_icethkness = []\n",
    "for num in range(0, len(ice_thickness)):\n",
    "    date_time = convert_to_datetime('Year', 'Month', num, ice_thickness)\n",
    "    datetime_icethkness.append(date_time)\n",
    "ice_thickness['DateTime'] = datetime_icethkness\n",
    "\n",
    "# Set index to DateTime\n",
    "ice_thickness = ice_thickness.set_index('DateTime')\n",
    "\n",
    "\n",
    "# Sort the data by DateTime (ascending chronological order)\n",
    "ice_thickness = ice_thickness.sort_index()\n",
    "\n",
    "# Delete the Year and Month columns as they are now unnecessary\n",
    "ice_thickness = ice_thickness.drop('Year', axis=1)\n",
    "ice_thickness = ice_thickness.drop('Month', axis=1)\n",
    "\n",
    "# Masking Missing Values from Min_thkns. Refer to Above to check missing values.\n",
    "min_thkns = ice_thickness['Min_thkns']\n",
    "mask_min_thkns = min_thkns > 0\n",
    "min_thkns = min_thkns[mask_min_thkns]\n",
    "\n",
    "# Creating Average Thickness DataFrame:\n",
    "avg_thkns = ice_thickness['Avg_thkns']\n",
    "\n",
    "# Creating Max Thickness DataFrame:\n",
    "max_thkns = ice_thickness['Max_thkns']\n",
    "\n",
    "# Creating the SD Thickness DataFrame:\n",
    "sd_thkns = ice_thickness['SD_thkns']\n",
    "\n",
    "# Creating the lattitude DataFrame for ice thickness:\n",
    "lat_thkns = ice_thickness['Lat']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3> Setting up Data for Precipitation </h3>\n",
    "\n",
    "<strong>cmap-mean.csv</strong> has LOTS of data that are unnecessary for this data analysis.\n",
    "\n",
    "We only need data from lat 60 to 90 since that's the average lattitude we're searching for.\n",
    "This is because the Arctic is around 76' latttiude, and we want some leniency in the collection of our data.\n",
    "Therefore, we gather from 60' lat to 90' lat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5432832 = total number of data in original csv file.\n",
      "905472 = the number of leftover data-points after filter\n",
      "              lat     lon  precip\n",
      "time                             \n",
      "1979-01-01  88.75    1.25    0.21\n",
      "1979-01-01  88.75  253.75    0.39\n",
      "1979-01-01  68.75  186.25    1.37\n",
      "1979-01-01  86.25   38.75    0.29\n",
      "1979-01-01  66.25  351.25    3.91\n",
      "...           ...     ...     ...\n",
      "2022-08-01  68.75    3.75    0.86\n",
      "2022-08-01  68.75    6.25    1.00\n",
      "2022-08-01  68.75    8.75    1.34\n",
      "2022-08-01  68.75   13.75    2.33\n",
      "2022-08-01  61.25  358.75    1.40\n",
      "\n",
      "[905472 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Setting up data for Precipitation\n",
    "\n",
    "# Reading the raw cmap-means.csv.\n",
    "# Objective: Filter out all data outside of lattitude 60 ~ 90\n",
    "precipitation = pd.read_csv('./Precipitation/cmap-mean.csv')\n",
    "print(f\"{len(precipitation)} = total number of data in original csv file.\")\n",
    "\n",
    "\n",
    "# There's more data thats outside of the 60 ~ 90 range. \n",
    "# To optimize the code, it is better to make the if condition 60 and below.\n",
    "\n",
    "for num in range(0, len(precipitation)):\n",
    "    if precipitation.iloc[num]['lat'] < 60:\n",
    "        precipitation = precipitation[:num]\n",
    "\n",
    "        break\n",
    "\n",
    "print(f\"{len(precipitation)} = the number of leftover data-points after filter\")\n",
    "\n",
    "# Need to set the YYYY-MM-DD as the index for the precipitation data.\n",
    "# Doing this now, because iterating through a DateTime is difficult for the procedures above.\n",
    "precipitation = precipitation.set_index('time')\n",
    "\n",
    "# Sort the data by DateTime (ascending chronological order)\n",
    "precipitation = precipitation.sort_index()\n",
    "\n",
    "# Create DataFrame for the precipitation\n",
    "precip_data = precipitation['precip']\n",
    "\n",
    "# Create lattitude data for the precipitation\n",
    "lat_precip = precipitation['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style='color:cyan;'> Only run this code if you need to save a new .csv file (with <strong>filtered</strong> data from <strong>cmap-mean.csv</strong>))</h4>\n",
    "\n",
    "Export to a csv file with wanted range of data. <br>\n",
    "Un-necessary, but am doing this so we don't have a humongous data set to download.<br>\n",
    "<p><code>precipitation.to_csv(\"./Precipitation/filtered_precipitation_data.csv\", index=False)</code></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Data Analysis - Plotting PARAMETER1 vs PARAMETER2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f1ccfe1132665631f97eb5b941ca4b93e2d3b7ae0534c7bcd7a7028a78ff9c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
